---
title: "Titanic-in-R"
author: "Everett Robinson"
date: "June 5, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(stringr)
library(caret)
library(doParallel)
```

## Titanic in R

This is my submission for the Kaggle titanic competition: <https://www.kaggle.com/c/titanic>. It leverages the caret package in R, and uses many different models that ultimately have their predictions stacked into a final ensemble model. I have had a lot of success using random forests on the Coursera Practical Machine Learning project <https://www.coursera.org/learn/practical-machine-learning>. My hope is that this combined model will perform better than any one of the models individually.

### Data Import and Exploration
The first step is to import the provided training and test data sets.

```{r import}
training <- read.csv("../input/train.csv")
testing <- read_csv("../input/test.csv")

dim(training)
dim(testing)
```

Ideally the training data could be split into a new training set and a cross validation set resuting in a standard split of approximately 75% training and 25% cross validation data. This would allow us to examine the out of sample error on a wide variety of models and parameters before commiting to one of them and running it on the test data. Unfortunately at only 891 rows of data, I have a gut feeling that we will need as much training data as we can get away with. I will not split off a cross validation data set from the training data for this project, and instead utilize caret's buildt in capacity for resampling or k-fold crossvalidation. 

Ultimately I will submit the model that performs best on the provided test data set. This should work out in the end, because to the best of my knowledge, Kaggle has reserved another 418 rows of data for final model testing. That can be the real test of whether my model overfitted or not. The only downside is that we'll need to wait three years to find out.

Before we get ahead of ourselves, we should do some data exploration. We'll need to know what data we are actually working with:
```{r column_names}
names(training)
```

We have a numeric PassengerId column that appears to start at 1 and increase by one sequencially to 891 based on the min, max. and median values. This is the sort of data that appears to mostly matter for book keeping when we go to submit the predictions at the end, and that we shouldn't expect to be useful when training. In the worst case it may play a significant role in classification and lead to overfitting. For these reasons we will exclude it from the training steps.

We know from the competition page that he rest of the data is the following:


+---------+----------------------------------------------+----------------+
|Variable |	Definition                                   | Key            |
+=========+==============================================+================+
|survival | Survival                                     | 0 = No,        |
|         |                                              | 1 = Yes        |
+---------+----------------------------------------------+----------------+
|pclass 	| Ticket class                                 | 1 = 1st,       |
|         |                                              | 2 = 2nd,       |
|         |                                              | 3 = 3rd        |
+---------+----------------------------------------------+----------------+
|sex 	    | Sex                                          |                |
+---------+----------------------------------------------+----------------+
|Age 	    | Age in years                                 |                |
+---------+----------------------------------------------+----------------+
|sibsp 	  | num of siblings / spouses aboard the Titanic |                |	
+---------+----------------------------------------------+----------------+
|parch 	  | num of parents / children aboard the Titanic |	              |
+---------+----------------------------------------------+----------------+
|ticket 	| Ticket number                                |                |
+---------+----------------------------------------------+----------------+
|fare 	  | Passenger fare                               |                |
+---------+----------------------------------------------+----------------+
|cabin 	  | Cabin number                                 |                |
+---------+----------------------------------------------+----------------+
|embarked | Port of Embarkation                          | C = Cherbourg, |
|         |                                              | Q = Queenstown,|
|         |                                              | S = Southampton|
+---------+----------------------------------------------+----------------+

**Variable Notes**

**pclass**: A proxy for socio-economic status (SES)
1st = Upper
2nd = Middle
3rd = Lower

**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5

**sibsp**: The dataset defines family relations in this way...
Sibling = brother, sister, stepbrother, stepsister
Spouse = husband, wife (mistresses and fiancÃ©s were ignored)

**parch**: The dataset defines family relations in this way...
Parent = mother, father
Child = daughter, son, stepdaughter, stepson
Some children travelled only with a nanny, therefore parch=0 for them.

The first two variables Survived and Pclass are exactly as described.
```{r}
unique(training$Survived)
unique(training$Pclass)
```
We know from above that Pclass is a categorical variable where the values are first, second, and third class. There are no other possible values. Because Pclass is categorical we can convert it into three separate dummy variable columns later during preprocessing. 


```{r}
summary(training)
```

We can see fromthe summary table that Sex is strictly male and female, and skews towards males. There doesn't appear to be any missing values, and the data is good the way it is.

```{r}
ggplot(data = training) + geom_bar(aes(x = Sex)) + ggtitle("Distribution of Gender on the Voyage")
```

Age is a bit of a different story. There are 177 rows for which age is not available. We will probably need to find a way to impute values for these. 

```{r}
ageData <- training
ageData$AgeBins <- ageData$Age %>% cut_interval(length = 2.5)
ageData %>% group_by(AgeBins) %>% ggplot() + geom_bar(aes(x = AgeBins)) + coord_flip() + ggtitle("Count of Passengers by Age")
```

The spread of ages appears to be almost normally distributed around the age of 30. Due to the reatively low counts of passengers at the younger and older ages, we should expect more variability in survival rates and be less surprised when they differ from other age groups.

Now lets see if there is some correlation between age and survival rate:
```{r}
ageData %>% group_by(AgeBins) %>% summarise(meanSurv = mean(Survived)) %>% ggplot() + geom_col(aes(x = AgeBins, y = meanSurv)) + coord_flip() + ggtitle("Mean Survival Rate by Age")
```

We can see that the one eighty year old survived, making that bar stand out. We also see that young children and early adolescents seem to have done well, and that survival generally decreases with age. Let's break this down by gender:
```{r}
ageData %>% filter(Sex == "male") %>% group_by(AgeBins) %>% summarise(meanSurv = mean(Survived)) %>% ggplot() + geom_col(aes(x = AgeBins, y = meanSurv)) + coord_flip() + ggtitle("Survival Rates for Males by Age")
```

The above pattern is far more striking when we isolate for males. Boys did better, but survival rates tend to crash for those above the age of 15. 

```{r}
ageData %>% filter(Sex == "female") %>% group_by(AgeBins) %>% summarise(meanSurv = mean(Survived)) %>% ggplot() + geom_col(aes(x = AgeBins, y = meanSurv)) + coord_flip() + ggtitle("Survival Rates for Females by Age")
```
For women, the trend is essentially non-existant, and the variability overwhelms any signal that might exist in the noise.

It's good to know that women and children were indeed were indeed prioritized on the titanic and that wasn't just a line from the movie. This also means we shoud expect age and gender to play major roles in survival later in ou trained models.

Next lets see if there are any relations between the SibSp, Parch, and survival:

```{r}
training %>% group_by(SibSp, Parch) %>% summarise(meanSurv = mean(Survived)) %>% ggplot() + geom_tile(aes(x = Parch, y = SibSp, fill = meanSurv))
```
In general, it looks like the larger the family is, the poorer the survival rate. When Parch is greater or equal to 4, which means people with lots of kids, or possibly multigenerational families, survival seems to be quite low. People who had lots of siblings plus spouses on board also appear to have fared more poorly than smaller families.

```{r}
training %>% group_by(SibSp, Parch) %>% summarise(meanSurv = mean(Survived)) %>% ggplot() + geom_tile(aes(x = Parch, y = SibSp, fill = meanSurv))
```

Next we can look at the survival rate by fare:

```{r}
fareData <- training
fareData$FareBins <- training$Fare %>% cut_interval(length = 25)
fareData %>% group_by(FareBins) %>% summarise(meanSurv = mean(Survived)) %>% ggplot() + geom_col(aes(x = FareBins, y = meanSurv)) + coord_flip() + ggtitle("Survival Rate by Fare")
```

Generally it appears as though the higher the fare, the better the chances of survival. This is likely because higher fares correlate to cabins and sleeping arrangements closer to the top of the ship.

```{r}
fareData %>% group_by(FareBins) %>% summarise(count = n()) %>% ggplot() + geom_col(aes(x = FareBins, y = count)) + coord_flip() + ggtitle("Count of Passengers by Fare")
```

It's also true that there are far more low fares than higher ones. This could mean that the people with the lowest fares occupied smaller and more densely packed cabins. If this is the case, that could also negatively affect survival as there would be more people clamouring to get to safety in the corridors where these smaller cheaper cabins are situated. 

And now let's look at the survival rate by port of embarkation:
```{r}
training %>% group_by(Embarked) %>% summarise(meanSurv = mean(Survived)) %>% filter(Embarked != "") %>% ggplot() + geom_col(aes(x = Embarked, y = meanSurv)) + coord_flip() + ggtitle("Survival Rate by Port of Embarkation")
```

There seems to be slightly higher survival of passengers who embarked at Cherbourg. I'm not sure why this might be the case, and it may not even be a significant difference.

Overall, it appears there will be lots of correlations between survival and the other elements of the data for the machine learning algorithms to use when making predictions. Even so, the next steps will be to clean up the existing features and create some new ones that might help improve them further.

### Data Cleaning and Feature Engineering

The first feature that jumped out at me for creation when exploring the data is a person's title. We can see from the names that there are far more than just Miss., Mrs. and Mr.:

```{r}
# The following regex extracts the text between ", " or ", the " and ". "
titles <- str_extract_all(training$Name, "((, )|(, the )).{2,10}(\\. )")
titles <- str_sub(titles, 3, str_length(titles) - 1)

as_tibble(titles) %>% count(value)
```

Most of them are pretty uncommon however, with only "Master."", "Miss."", "Mr."", and "Mrs."" accounting for more than 10 indviduals each. This means we should probably find a way to group these titles. For this analysis I will use the following:

```{r}
simplify_titles <- function(data) {
  
  simple_titles <- tribble(
    ~raw_title, ~title,
    "Capt.", "Ranked",
    "Col.", "Ranked",
    "Don.", "Nobility",
    "Dona.", "Nobility",
    "Dr.", "Professional",
    "Jonkheer.", "Nobility",
    "Lady.", "Nobility",
    "Major.", "Ranked",
    "Master.", "Professional",
    "Miss.", "Miss",
    "Mlle.", "Miss",
    "Mme.", "Mrs",
    "Mr.", "Mr",
    "Mrs.", "Mrs",
    "Ms.", "Miss",
    "Rev.", "Professional",
    "Sir.", "Nobility",
    "the Countess.", "Nobility"
  )
  
  return(data %>% left_join(simple_titles))
}
```

We will wrap the above transformations into a function that can be applied consistently to any data.

```{r}
create_titles <- function(data) {
  # The following regex extracts the text between ", " or ", the " and ". "
  data <- data %>% transform(raw_title = str_extract(Name, "((, )|(, the )).{2,10}(\\. )")) %>% 
    transform(raw_title = str_sub(raw_title, 3, str_length(raw_title) - 1)) %>% simplify_titles() %>% select(-raw_title)

  return(data)
}
```

The next steps are to extract meaningful information from the ticket data. It looks to me like when the ticket is not just a number, it has some prefix on the front separated by a space from the numerical part of the ticket:
```{r}
ticket_components <- training$Ticket %>% str_split(" ")
head(ticket_components)
```

This means we can extract the prefix using the following regex:
```{r}
head(training$Ticket %>% str_extract("^.+\\s")) %>% str_trim()
```

There are a lot of ticket prefixes that appear to mean the same thing even though they are not exactly the same:
```{r}
training$Ticket %>% str_extract("^.+\\s") %>% str_trim() %>% as_tibble() %>% count(value)
```

These differences between ticket prefixes are more complex than they first appear. Originally I just thought to replace all the periods and forward slashes with nothing, as that will reduce all of the prefixes such as "A/4", "A/4.", and "A4." to "A4" and successfully unify them into a single category. Unfortunately this also seems to differentiate legitimately separated prefixes such as "S.C/A.4." from "SC" or "A4" and "C.A./SOTON" from "C.A." and other rows containing "SOTON". This possibility for a ticket to have multiple prefixes suggests that we will need to take a more nuanced approach. Instead I will create a function that identifies if a prefix contains the following key values within it: A4, A5, AH, CA, FC, PC, PP, SC, SOC, SOP, SOTON, SP, SW, O2, OQ, WC, and WEP.

```{r}
create_ticket_prefixes <- function(data) {
  data <- data %>% transform(ticket_prefix = str_extract(data$Ticket, "^.+\\s") %>% str_trim() %>% str_replace_all("(\\.)|/", "") %>% str_replace_na())
  
  #A4
  data <- data %>% transform(ticket_A4 = factor(str_detect(data$ticket_prefix, "A4")))  
  
  #A5
  data <- data %>% transform(ticket_A5 = factor(str_detect(data$ticket_prefix, "A5")))
  
  #AH
  data <- data %>% transform(ticket_AH = factor(str_detect(data$ticket_prefix, "AH")))
  
  #CA
  data <- data %>% transform(ticket_CA = factor(str_detect(data$ticket_prefix, "CA")))
  
  #FC
  data <- data %>% transform(ticket_FC = factor(str_detect(data$ticket_prefix, "FC")))
  
  #PC
  data <- data %>% transform(ticket_PC = factor(str_detect(data$ticket_prefix, "PC")))
  
  #PP
  data <- data %>% transform(ticket_PP = factor(str_detect(data$ticket_prefix, "PP")))
  
  #SC
  data <- data %>% transform(ticket_SC = factor(str_detect(data$ticket_prefix, "SC")))
  
  #SOC
  data <- data %>% transform(ticket_SOC = factor(str_detect(data$ticket_prefix, "SOC")))
  
  #SOP
  data <- data %>% transform(ticket_SOP = factor(str_detect(data$ticket_prefix, "SOP")))
  
  #SOTON
  data <- data %>% transform(ticket_SOTON = factor(str_detect(data$ticket_prefix, "(SOTON|STON)")))
  
  #SP
  data <- data %>% transform(ticket_SP = factor(str_detect(data$ticket_prefix, "SP")))
  
  #SW
  data <- data %>% transform(ticket_SW = factor(str_detect(data$ticket_prefix, "SW")))
  
  #O2
  data <- data %>% transform(ticket_O2 = factor(str_detect(data$ticket_prefix, "O2")))
  
  #OQ
  data <- data %>% transform(ticket_OQ = factor(str_detect(data$ticket_prefix, "OQ")))
  
  #WC
  data <- data %>% transform(ticket_WC = factor(str_detect(data$ticket_prefix, "WC")))
  
  #WEP
  data <- data %>% transform(ticket_WEP = factor(str_detect(data$ticket_prefix, "WEP")))
  
  data <- data %>% select(-ticket_prefix)
  
  return(data)
}
```


Now we can find a way to extract some meaningful information from the Cabin variable:
```{r}
training %>% count(Cabin)
```

We can see that for most people no Cabin data is available. For the rest it seems like most cabins are simply a letter followed by a number, but there are some exceptions. There are several individuals who appear to have multiple cabins:
```{r}
training$Cabin[training$Cabin %>% str_detect(" ")] %>% unique()
```

Generally it appears as though the cabin letters are all the same for these individuals, and that for the exceptions "F G73", "F E69", and "F G63", there is only one cabin that has numbers following it. I will therefore extract only the cabin letter comming from the first cabin that has a number following it. All NA cabins will be converted to "Unknown". 
```{r}
create_cabin_letters <- function(data) {
  data <- data %>% transform(cabin_letter = str_extract(data$Cabin, "[A-Z]\\d{1,3}") %>% str_extract("[A-Z]") %>% str_replace_na(replacement = "Unknown"))
  
  return(data)
}
```

Now lets add some complementary features to the known family variables SibSp and Parch:
```{r}
create_family_size <- function(data) {
  data <- data %>% transform(family_size = SibSp + Parch)
  
  return(data)
}

create_travelled_alone <- function(data) {
  data <- data %>% transform(travelled_alone = (SibSp + Parch) == 0)
  
  return(data)
}
```

Next we will make sure that the Pclass variable is treated as a categorical variable instead of a continuous one:
```{r}
create_categorical_pclass <- function(data) {
  data$Pclass <- factor(data$Pclass)
  levels(data$Pclass) <- c("first", "second", "third")
  
  return(data)
}
```

That should so it for the manual preprocessing and feature creation steps I had in mind. We should wrap up all of the above functions into a larger function so that we know they were applied consistently to the different datasets.
```{r}
engineer_features <- function(data) {
  data <- data %>% create_titles() %>% create_ticket_prefixes() %>% create_cabin_letters() %>% 
    create_family_size() %>% create_travelled_alone() %>% create_categorical_pclass()
  
  return(data)
}

names(engineer_features(training))
```

Next we will drop the feature columns when we have already processed them into more useful features, or when they appear as though they will contribute to overfitting:
```{r}
drop_features <- function(data) {
  data <- data %>% select(-c(PassengerId, Name, Ticket, Cabin))
  
  return(data)
}

names(drop_features(engineer_features(training)))
```

We will start by applying the previous data cleaning and feature engineering steps to the training and test data sets.
```{r}
clean_training <- drop_features(engineer_features(training))
clean_training$Survived <- factor(clean_training$Survived) # Convert Survived to a factor so that the predictions are discrete.
clean_testing <- drop_features(engineer_features(testing))
```

```{r}
clean_training_preProc <- preProcess(clean_training, method = c("knnImpute", "pca"))
clean_training <- predict(clean_training_preProc, clean_training)

clean_testing <- predict(clean_training_preProc, clean_testing)
```

###Model Training


We will set up a cluster to parallelize the training steps for performance reasons
```{r}
cl <- makeCluster(detectCores())
registerDoParallel(cl)
```

Random Forest:
```{r, echo = FALSE}
set.seed(763622)

rf_model <- train(Survived ~ ., method = "rf", tuneLength = 10, data = clean_training)
```

Gradient Boosting:
```{r, echo = FALSE}
set.seed(503878)

gbm_model <- train(Survived ~ ., method = "gbm", tuneLength = 5, data = clean_training)
```

SVM Radial with Class Weights:
```{r, echo = FALSE}
set.seed(227837)

svmradial_model <- train(Survived ~ ., method = "svmRadialWeights", tuneLength = 5, data = clean_training)
```

Bagged AdaBoost:
```{r, echo = FALSE}
set.seed(451039)

adabag_model <- train(Survived ~ ., method = "AdaBag", tuneLength = 5, data = clean_training)
```

Tree Models from Genetic Algorithms:
```{r, echo = FALSE}
set.seed(810148)

evtree_model <- train(Survived ~ ., method = "evtree", tuneLength = 5, data = clean_training)
```

Neural Network:
```{r, echo = FALSE}
set.seed(19417)

nnet_model <- train(Survived ~ ., method = "nnet", tuneLength = 5, data = clean_training)
```

Penalized Logistic Regression:
```{r, echo = FALSE}
set.seed(58276)

plr_model <- train(Survived ~ ., method = "plr", tuneLength = 5, data = clean_training)
```

Stacked Model (Majority Wins):
```{r, echo = FALSE}
set.seed(636098)

create_stacked_df <- function(data) {
  rf_pred <- predict(rf_model, data)
  gbm_pred <- predict(gbm_model, data)
  svmradial_pred <- predict(svmradial_model, data)
  adabag_pred <- predict(adabag_model, data)
  evtree_pred <- predict(evtree_model, data)
  nnet_pred <- predict(nnet_model, data)
  plr_pred <- predict(plr_model, data)
  
  stacked <- tibble(rf_pred, gbm_pred, svmradial_pred, adabag_pred, evtree_pred, nnet_pred, plr_pred)
  return(stacked)
}

# Any sum higher than a 3 means a majority of the seven models predicted survival.
stacked_predictions <- create_stacked_df(clean_testing) %>% transmute(Survived = as.numeric(rowSums(. == 1) > 3))

submission <- tibble(PassengerId = testing$PassengerId, Survived = stacked_predictions$Survived)
write_csv(submission, "submission.csv")
```

